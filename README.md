# 초·중·고등학교 급식 트렌드 분석과 외부 지표 연계 🍱🍽️
- [streamlit link](https://school-lunch.streamlit.app/)
<img width="566" alt="image" src="https://github.com/user-attachments/assets/e65e4d3b-3b97-4523-a26a-fdfb9315adb8" />

## :rocket: 프로젝트 개요

- **데이터 범위:** 전국 학교의 점심 급식 메뉴 및 영양소 정보
- **시기:** 2021년 ~ 현재
- **목표**
  **=> 전국 초·중·고등학교의 급식 메뉴와 영양정보를 분석하고, 학생 수·예산안 등 외부 지표와의 연계를 통해 인사이트를 도출하며, 이를 기반으로 자동화된 평가 분석 리포트 생성을 목표로 합니다.**

## 🗂️ 수집 데이터

### 1. 메인 데이터:

- **데이터 출처 및 링크:** 나이스 교육정보 개방 포털, [급식식단정보 API](https://open.neis.go.kr/portal/data/service/selectServicePage.do?page=1&rows=10&sortColumn=&sortDirection=&infId=OPEN17320190722180924242823&infSeq=2)
- **데이터 크기 예상:** 약 30GB (4년 기준)
- **수집 주기 / 업데이트 주기:** @daily
- **제공 포맷 (예: JSON, CSV, XML, API 등):** CSV, JSON, API

### 2. 보조 데이터:
- 자치구별 학교급식운영 예산안 [지방교육재정 알리미](https://www.eduinfo.go.kr/portal/open/openData/dataSetPage.do#none;)
- **수집 주기 / 업데이트 주기:** 1년 
- 권장 영양소 기준치 데이터 [서울특별시교육청보건안전진흥원](https://bogun.sen.go.kr/fus/MI000000000000000562/html/cont0010v.do)

## 💻 분석 주제

1. 학교별 급식 메뉴

2. 급식 통계 및 트렌드

   - 메뉴 인기 순위: 1년동안 출현 빈도 기준 Top 20 메뉴
   - New 메뉴 탐색: 전년도 비교하여 새로 생긴 메뉴 20가지
   - 지역별·학교급별 급식 평균 메뉴 수를 확인하여 급식의 다양성 분석

3. 급식 영양 균형 분석 달력 : 단백질/지방 부족 영양소를 일자별로 한눈에 확인 가능한 달력으로 시각화(초/중/고 권장 영양소 기준)

**추후 추가 사항**

4. 전국 시도별 비교: 급식 품질 vs 예산/학생수 연계 - 보조 데이터 필요 + 학생 1인당 급식비 예산 분석 --> 분석 방향: 지역별로 1인당 급식비 추정 (예산 ÷ 식 수) / 메뉴 다양성, 영양소 질과 비교 → 예산이 높은 곳이 더 나은 식단인가?)+ 급식 품질과의 관계 비교를 위한 시각화 -> 영양수준의 충실성, 메뉴의 다양성 평가 기준으로

5. 지역별 특별 메뉴 (전국단위 분석)

6. 연도별 특별 메뉴 (시계열 분석)

## 📌 개념의 조작적 정의 요구사항 (Data Featuring)

1. 영양 수준의 충실성의 기준 선정

![Image](https://github.com/user-attachments/assets/21745637-fe51-45b7-ad66-511bdae69684)

| 평가                   | 기준 설명                  |
| ---------------------- | -------------------------- |
| ⭐⭐⭐⭐⭐ (매우 양호) | 부족 영양소 수: 3.5 이하   |
| ⭐⭐⭐ (보통)          | 부족 영양소 수: 5 이하     |
| ⭐ (심각)              | 부족 영양소 수: 6 ~ 9 이하 |

| 평가                   | 기준 설명                          |
| ---------------------- | ---------------------------------- |
| ⭐⭐⭐⭐⭐ (매우 좋음) | 에너지 권장량 700~900사이          |
| ⭐⭐⭐ (보통)          | 권장량 - 700이하 또는 900~1200사이 |
| ⭐ (매우 나쁨)         | 권장량 - 1200이상                  |

2. 메뉴 다양성의 기준 선정

| 평가                   | 기준 설명            |
| ---------------------- | -------------------- |
| ⭐⭐⭐⭐⭐ (매우 좋음) | 총 메뉴가 7가지 이상 |
| ⭐⭐⭐⭐ (좋음)        | 총 메뉴가 6가지      |
| ⭐⭐⭐ (보통)          | 총 메뉴가 5가지 이하 |

3. 급식 품질의 기준 선정 - **위 일단위의 영양 평가와 메뉴 다양성을 합쳐서 월 평균으로 계산하여 평가**

- 15점 만점 기준 11점 이상 "품질 매우 좋음"
- 11점 미만 7점 이상"품질 좋음"
- 7점 미만"품질 보통"

## 📊 Airflow 활용

### DAG 설계 방향

### DAG 설명

1. data_import.py
   1. school_lunch : 데이터를 읽어오고 처리한 뒤 저장 자동화
      - load_json_from_gcs : gs에 저장한 학교코드 및 구분 json 파일 읽어오기
      - get_api : url생성 및 데이터 병합
      - fetch_json : 생성된 url를 이용한 opneApi데이터 호출
      - pre_parquet : 데이터 전처리
      - upload_partitioned_parquet_to_gcs : 완료된 데이터를 gs에 업로드
   2. date_edit : bigquery 생성을 위한 추가 데이터 변형
      - date, nut_dict의 타입, 언어 변경

### 저장소

- Google Storage : 데이터 parquet들을 날짜로 partition하여 저장
- BigQuery : gs의 parquet을 이용한 Table Schema 생성

### 알림 설정

- Discord 웹후크 기능으로 데이터 처리 중 오류 발생, 작업 완료 시 팀 채널에 알림 활성화

### 기타

## 💠 데이터 아키텍쳐

### 조직도

<img width="920" alt="image" src="https://github.com/user-attachments/assets/29cea23f-1280-4f46-b83b-637237f23554" />

---

## 개발 진행 정리

### v0.1

1. 프로젝트 시작, 깃 레퍼지토리 생성 및 개발 방향 및 계획 수립

### v0.2

1. 데이터 설정, 로컬 환경에서의 import와 전처리 코드 개발

### v0.5

1. 0.2버전의 과정을 일관화
2. 저장소를 로컬이 아닌 gs로 연결
3. 총 과정을 airflow 서버로 올려서 데이터 수집 자동화 진행

### v0.9

1. 로컬에서의 streamlit 프로토타입 작성
2. 실제 서버 가동 및 gcp와의 연결 작업
3. 데이터를 이용한 인사이트 도출 계획
4. 필요한 코드 개발

## git repository 요약

1. code = [school_code.py : 학교의 이름과 구분 데이터를 가져와 gs에 저장. 1회 가동 /
   school_lunch.py : 급식 정보 데이터 import 및 전처리, gs에 저장까지에 대한 코드]

2. dags = [data_import.py : school_lunch.py파일의 쉘 실행 자동화 dags. 로컬 dags에 가상링크로 연결하여 사용]

3. temp = test나 임시 코드, 구 버전 미사용 코드 저장

## 📖 회고록

### 배형균
- 좋았던 점

2차 프로젝트에서는 WBS 수립하고, 개발 단계에서 github를 활용하면서 빠른 피드백이 이루어졌고, 데이터 수집 - 적재 - 전처리 - 분석 - 시각화까지 전 과정에 참여할 수 있어서 좋았습니다. (그동안 배운 툴을 사용한 것 도 좋았습니다. / airflow, spark, GCP, BigQuery, Streamlit 등)

- 아쉬운 점

데이터 전처리 후 데이터 분석 도중 이상값들 해결 위한 시간이 많이 소요되면서, 외부 데이터와 연계하여 분석을 실행하지 못해 아쉬웠고, 데이터 전처리의 중요성을 느꼈습니다.

### 백지원
- 좋았던 점

깃 허브 branch를 체계적으로 사용해서 merge 충돌이 많이 안 일어난 것, 디스코드를 통한 즉각적인 의견 및 코드 교환으로 저번 프로젝트보다 팀 플레이가 나아져서 좋았습니다.

- 아쉬운 점

데이터 전처리 과정을 맡으면서 bigquery 에 사용할 수 없던 type을 고려하지 않고 코딩, 실행해서 다시 전처리를 해야했던 것이 아쉬웠고, 시간 안에 최종 목표까지 완벽하게 해내지 못 한 것이 아쉬웠습니다.

### 조성근
- 좋았던 점

Github Repo 를 적극적으로 활용, Issue & Milestone으로 진행상황 공유 및 관리, Branch 버전별 · 용도별 관리에 유의하였음
지난 프로젝트 진행 시 아쉬웠던 부분의 집중 개선!

- 아쉬운 점

메뉴 데이터 클리닝 시 AI를 활용한 형태소 분석에 대해 정보가 부족했고 및 주저하였음

### 조민규
- 좋았던 점

상세한 개발 계획 수립과 체계적인 git repository 구성
spark, airflow 같은 기술을 목적을 가지고 사용한 경험

- 아쉬운 점

개발 전반에 걸친 gpt에 대한 큰 의존성
데이터 수집, 처리과정에 있어서 모니터링과 사전 조사의 미흡함
사용 기술 스택에 대한 심도있는 이해의 부족
