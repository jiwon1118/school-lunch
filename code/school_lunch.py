import requests
import pandas as pd
from datetime import datetime, timedelta
from google.cloud import storage
import pyarrow
import json
import re
import tempfile
import os

# gcsì—ì„œ í•™êµ ì½”ë“œ json íŒŒì¼ì„ ì½ì–´ì˜¤ê¸°
def load_json_from_gcs(bucket_name: str, blob_name: str):
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)

    json_str = blob.download_as_text(encoding='utf-8')
    data = json.loads(json_str)
    df = pd.DataFrame(data)
    return df

# apiì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸°
def get_api():
    df = load_json_from_gcs("school-lunch-bucket", "lunch_menu/school_data.json")
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    school_df = df[['ATPT_OFCDC_SC_CODE', 'SD_SCHUL_CODE', 'SCHUL_KND_SC_NM']].copy()
    # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë³€ê²½ (ì„ íƒ)
    school_df.columns = ['ì§€ì—­ì½”ë“œ', 'í•™êµì½”ë“œ', 'í•™êµêµ¬ë¶„']
    
    # í™˜ê²½ì„¤ì •
    API_KEY = '261957623ead45779884d5b6e27385cf' # ë³¸ì¸ API_KEY ì…ë ¥
    EDU_CODE = 'B10'  # ì„œìš¸ êµìœ¡ì²­
    SCH_CODE = school_df[school_df['ì§€ì—­ì½”ë“œ'].str.upper() == EDU_CODE]['í•™êµì½”ë“œ']
    BASE_URL = 'https://open.neis.go.kr/hub/mealServiceDietInfo'
    DATE = datetime(2021, 3, 1)

    # ìµœì¢… DataFrame
    all_df = pd.DataFrame()

    # ğŸ‘‰ ë‚ ì§œ ë°˜ë³µ
    ymd = DATE.strftime('%Y%m')
    page = 1
    for school in SCH_CODE:
        params = {
            'KEY': API_KEY,
            'Type': 'json',
            'ATPT_OFCDC_SC_CODE': EDU_CODE,
            'SD_SCHUL_CODE': school,
            'MLSV_YMD': ymd,
            'MMEAL_SC_CODE': 2,
            'pIndex': page,
            'pSize': 1000
        }
        res = requests.get(BASE_URL, params=params)
        data = res.json()
        
        try:
            rows = data['mealServiceDietInfo'][1]['row']
        except (KeyError, IndexError):
            pass

        df = pd.DataFrame(rows)
        all_df = pd.concat([all_df, df], ignore_index=True)

        if len(rows) < 1000:
            pass
        else:
            page += 1
        
    # í•™êµ êµ¬ë¶„ ì¶”ê°€
    school_merge_df = school_df[['í•™êµì½”ë“œ', 'í•™êµêµ¬ë¶„']]

    # ë³‘í•©
    all_df = all_df.merge(school_merge_df, how='left', left_on='SD_SCHUL_CODE', right_on='í•™êµì½”ë“œ')
    # 'LV' ì»¬ëŸ¼ìœ¼ë¡œ ì´ë¦„ ë³€ê²½
    all_df.rename(columns={'í•™êµêµ¬ë¶„': 'LV'}, inplace=True)
    
    return all_df


def pre_parquet(df):

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ìœ ì§€
    keep_cols = [
        "MLSV_YMD",           # ê¸‰ì‹ ë‚ ì§œ
        "ATPT_OFCDC_SC_CODE", # êµìœ¡ì²­ ì½”ë“œ
        "ATPT_OFCDC_SC_NM",   # êµìœ¡ì²­ ì´ë¦„
        "SD_SCHUL_CODE",      # í•™êµ ì½”ë“œ
        "SCHUL_NM",           # í•™êµ ì´ë¦„
        "DDISH_NM",           # ê¸‰ì‹ ë©”ë‰´
        "CAL_INFO",           # ì¹¼ë¡œë¦¬ ì •ë³´
        "NTR_INFO",           # ì˜ì–‘ì†Œ ì •ë³´
        "MLSV_FGR",           # ê¸‰ì‹ ì¸ì› ìˆ˜
        "LV"                  # í•™êµ ì¢…ë¥˜
    ]
    df = df[keep_cols]
    
    # ë‚ ì§œ í˜•ì‹ ë³€í™˜
    df["DATE"] = pd.to_datetime(df["MLSV_YMD"], format="%Y%m%d")
    
    df = df.rename(columns={
        "ATPT_OFCDC_SC_CODE": "REG_C",  # ì§€ì—­ ì½”ë“œ
        "ATPT_OFCDC_SC_NM": "REG_N",    # êµìœ¡ì²­ ì´ë¦„
        "SD_SCHUL_CODE": "SCH_C",       # í•™êµ ì½”ë“œ
        "SCHUL_NM": "SCH_N",            # í•™êµ ì´ë¦„
        "MLSV_FGR": "COUNT",            # ê¸‰ì‹ ì¸ì› ìˆ˜
        })


    # ì¹¼ë¡œë¦¬ ìˆ˜ì¹˜ ì¶”ì¶œ
    df["CAL"] = df["CAL_INFO"].str.extract(r"([\d.]+)").astype(float)

    # ì˜ì–‘ì •ë³´ dict ë³€í™˜
    def parse_nutrition(info):
        try:
            parts = info.split("<br/>")
            return {
                kv.split(":")[0].strip(): kv.split(":")[1].strip()
                for kv in parts if ":" in kv
            }
        except:
            return {}

    df["NUT_DICT"] = df["NTR_INFO"].apply(parse_nutrition)

    # ë©”ë‰´ íŒŒì‹± ë° ì»¬ëŸ¼í™”
    def parse_menu_list(dish_text):
        try:
            return [item.strip() for item in dish_text.split("<br/>") if item.strip()]
        except:
            return []
        
    def clean_menu(menu_item):
        # í•œê¸€/ìˆ«ìë§Œ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì¶”ì¶œ (ì˜ë¬¸ìë‚˜ íŠ¹ìˆ˜ë¬¸ì ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ë§Œ)
        match = re.match(r'^[ê°€-í£0-9]+', menu_item)
        return match.group(0) if match else menu_item
    
    def remove_trailing_digits(menu_item):
        # ë’¤ì— ë¶™ì€ ìˆ«ìë§Œ ì œê±° (ì¤‘ê°„ ìˆ«ìëŠ” ìœ ì§€)
        return re.sub(r'\d+$', '', menu_item)
    
    df["MENU_LIST"] = df["DDISH_NM"].apply(parse_menu_list)
    df["MENU"] = df["MENU_LIST"].apply(lambda menus: [clean_menu(m) for m in menus])
    df["MENU"] = df["MENU"].apply(lambda menus: [remove_trailing_digits(m) for m in menus])
    df["MENU"] = df["MENU"].apply(list)
    rdf = df.explode("MENU").reset_index(drop=True)

    # ì •ë¦¬: ì›ë³¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì œê±°
    rdf.drop(columns=["MLSV_YMD", "CAL_INFO", "NTR_INFO", "DDISH_NM", "MENU_LIST"], inplace=True)
    return rdf


def upload_partitioned_parquet_to_gcs(df, bucket_name, base_path):
    df['DATE'] = pd.to_datetime(df['DATE'])
    df['DATE_YEAR'] = df['DATE'].dt.year.astype('int64')
    df['DATE_MONTH'] = df['DATE'].dt.month.astype('int64')

    # ì„ì‹œ ë””ë ‰í† ë¦¬ì— partition ì €ì¥
    with tempfile.TemporaryDirectory() as tmp_dir:
        df.to_parquet(tmp_dir, engine='pyarrow', index=False, partition_cols=['DATE_YEAR', 'DATE_MONTH'])

        client = storage.Client()
        bucket = client.bucket(bucket_name)

        # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ì„ GCSë¡œ ì—…ë¡œë“œ
        for root, _, files in os.walk(tmp_dir):
            for file in files:
                local_path = os.path.join(root, file)
                relative_path = os.path.relpath(local_path, tmp_dir)
                blob_path = os.path.join(base_path, relative_path).replace("\\", "/")  # Windows ê²½ë¡œ ëŒ€ì‘
                blob = bucket.blob(blob_path)
                blob.upload_from_filename(local_path)
                print(f"âœ… Uploaded to gs://{bucket_name}/{blob_path}")

# ë©”ì¸ ì‹¤í–‰
df = get_api()
rdf = pre_parquet(df)
upload_partitioned_parquet_to_gcs(rdf, 'school-lunch-bucket', 'lunch_menu')
